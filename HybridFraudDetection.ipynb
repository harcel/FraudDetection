{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Hybrid Fraud Detection Model\n",
    "\n",
    "Every fraud detection model in models.py by itself is a valuable model that is capable of finding suspicious service providers. The real power of a hybrid detection model is the combination of all these models into one. Often, the real fraudsters know how to stay under the radar on any aspect that is typically investigated. Combining all these models into one makes financial criminals that are just a little bit smarter than their obvious colleagues float to the surface.\n",
    "\n",
    "All models are run with a set of parameters and a weight and the scores are then combined, as explained in models_explanation.pdf. Here we show one particular run of the hybrid model, with one set of model parameters and model weights.\n",
    "\n",
    "This can be wrapped into a nice GUI in which the model parameters can be set and the results (visually) investigated. This demo just runs from the notebook. Feel free to see what happens when the model ingredients are tweaked!\n",
    "\n",
    "### Running the models\n",
    "Running the models depends on a set of parameters, and then the results are gathered into a data structure that is called the hitlist here. Below, the run is initialized and controlled by a function called \"process()\". The argument to the function is a dictionary of parameter settings of all models that need to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models, pickle\n",
    "import pandas as pd\n",
    "\n",
    "# The warnings filtered are the \"Setting with copy\" thing.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(modelsdict):\n",
    "    # The data needs to be read here. In general, this would likely be done elsewhere.\n",
    "    datafile = './data/mock_healthcare.pickle'\n",
    "    df = open(datafile, 'rb')\n",
    "    data = pickle.load(df)\n",
    "    df.close()\n",
    "\n",
    "    # Initialization of data structures for results. Outdata is a helper for if visualization in a GUI is desired.\n",
    "    hitlist = pd.DataFrame({'Provider_ID':[], 'Score':[], \"Model\":[], \"Monetary\":[], 'Weight':[]})\n",
    "    outdata = {}\n",
    "\n",
    "    allmodels = modelsdict.keys()\n",
    "    \n",
    "    for model in allmodels:\n",
    "        if   model == 'costs': hitlist, outdata = models.cost_per_member(data, modelsdict[model], hitlist, outdata)\n",
    "        elif model == 'billing':   hitlist, outdata = models.billing_pattern(data, modelsdict[model], hitlist, outdata)\n",
    "        elif model == 'weekends': hitlist, outdata = models.weekends_holidays(data, modelsdict[model], hitlist, outdata)\n",
    "        elif model == 'seasonality': hitlist, outdata = models.seasonality(data, modelsdict[model], hitlist, outdata)\n",
    "        elif model == 'increasing_revenue': hitlist, outdata = models.rising_revenue(data, modelsdict[model], hitlist, outdata)\n",
    "        elif model == 'combination': hitlist, outdata = models.combination_codes(data, modelsdict[model], hitlist, outdata)\n",
    "        elif model == 'periodic_often': hitlist, outdata = models.periodic_often(data, modelsdict[model], hitlist, outdata)\n",
    "        elif model == 'freely_billed': hitlist, outdata = models.freely_billed(data, modelsdict[model], hitlist, outdata)\n",
    "        elif model == 'fraction_expensive': hitlist, outdata = models.fraction_expensive(data, modelsdict[model], hitlist, outdata)\n",
    "        else:\n",
    "            print(\"Model not yet implemented!\")\n",
    "    \n",
    "    totals = total_score(hitlist)\n",
    "\n",
    "    return totals, hitlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models dict that is input to that function has dicts in it, one per model, with the model parameters. Below, one example is filled up and consequently run, resulting in what would be the hitlist for this specific set of options and parameters. Note that models do not have predefined defaults for the parameters, they *must* be specified. In a realistic implementation, the dictionary can be filled up by a GUI or some other, more user-friendly way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the model settings. All setting options are listed as well, if they exist.\n",
    "# If any model needs to be turned off, it can be removed. \n",
    "# The weight can be set to 0, in which case it will be run, but not count towards the total score. Results are available though.\n",
    "\n",
    "modelsdict = {\n",
    "    'costs': {'Grouping':'Per specialism',                   # Options: ['Per specialism', 'By determined peer group', 'Overall']\n",
    "              'Outlier definition': 'Above 90th percentile', # Options: ['Above 90th percentile', 'Above 95th percentile', 'Statistical outlier'],\n",
    "              'Weight': 1\n",
    "             },\n",
    "    'combination': {'Weight': 1},\n",
    "    'weekends': {'Weight': 1,\n",
    "                'Flag': 'too many'   # No other options implemented\n",
    "                },\n",
    "    'billing': {'Weight': 0.5},\n",
    "    'seasonality': {'Weight': 1},\n",
    "    'increasing_revenue': {'Weight': 2},\n",
    "    'periodic_often': {'Weight': 1, \n",
    "                'maxnumber': 2  # Any integer should work, but most don't work as well as say 2 or 3...\n",
    "                      },\n",
    "    'freely_billed':{'Weight': 1, \n",
    "                    \"Grouping\":'per_specialism',    # Options: 'overall' 'per_specialism'\n",
    "                    \"Group_codes\": \"per_procedure\", # Options: 'overall' 'per_procedure'\n",
    "                    \"Outlier\":'statistical'         # Options: 'statistical' 'percentile'\n",
    "                    },\n",
    "    'fraction_expensive': {'Weight': 1, \n",
    "                        \"Grouping\":'per_specialism',  # Options: 'overall', 'per_specialism'\n",
    "                        \"Ratio\": 'price',             # Options:['number', 'price']}\n",
    "                        \"Outlier\":'percentile'        # Options: 'statistical', 'percentile'\n",
    "                        }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To construct the total score after running all models:\n",
    "def total_score(hitlist):\n",
    "    \"\"\" \n",
    "    From the hitlist, construct the actual hitlist, with one entry per flagged provider.\n",
    "    \"\"\"\n",
    "\n",
    "    hitlist['scorexweight'] = hitlist.Score * hitlist.Weight\n",
    "\n",
    "    # Combine scores, monetary values and construct total scores and hitlist\n",
    "    per_prov = hitlist.groupby('Provider_ID')\n",
    "    weighted_total = per_prov.scorexweight.sum()\n",
    "    sum_weighted = weighted_total / per_prov.Weight.sum()\n",
    "\n",
    "    # For now, monetary amounts are *unweighted*\n",
    "    total_loss = per_prov.Monetary.sum()\n",
    "\n",
    "    # Number of flags\n",
    "    n_flags = per_prov.Model.count()\n",
    "\n",
    "    totals = pd.concat([sum_weighted, total_loss, n_flags], axis=1)\n",
    "    totals.rename(columns={0:'Weighted_score', 'Model':'N_flags'}, inplace=True)\n",
    "\n",
    "    # Total Score is a a 40-40-20 weighted sum of weighted score, monetary and N_flags\n",
    "    # It therefore, by definition, runs from 0 to 100.\n",
    "    max_w_score = totals.Weighted_score.max()\n",
    "    max_mon = totals.Monetary.max()\n",
    "    max_flags = totals.N_flags.max()\n",
    "\n",
    "    totals['Total_score'] = 40 * totals.Weighted_score / max_w_score + \\\n",
    "                            40 * totals.Monetary / max_mon + \\\n",
    "                            20 * totals.N_flags / max_flags\n",
    "\n",
    "\n",
    "    totals.sort_values('Total_score', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    return totals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, the model can be run:\n",
    "\n",
    "total_scores, hitlist = process(modelsdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
